{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bài tập 6\n",
    "\n",
    "Bùi Văn Hợp - 1712046"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Câu 1 (1 điểm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta có Deterministic Noise như định nghĩa nằm ở bản chất của từng tập Hypothesis có khả năng xấp xỉ tốt target, khá tương tự như phần bias trong phân tích Bias-Variance. Với cách suy nghĩ trên, nếu ta sử dụng 1 tập $H' \\subset H$, ta đang cố giới hạn lại khả năng của tập $H'$ so với tập $H$, bằng một cách nào đó, có thể là Regularization.\n",
    "\n",
    "Điều đó đồng nghĩa với việc khả năng một tập $H'$ đó bị overfitting giảm lại vì Stochastic Noise (nếu tập $H$ bị overfitting do vì chúng quá fit vào những phần lỗi Stochastic đó), nhưng ngược lại khả năng chúng có Deterministic Noise lại cao hơn, vì khả năng fit của $H'$ đã bị giới hạn và giảm xuống đi so với $H$, vậy nên Deterministic Noise của $H'$ sẽ cao hơn $H$.\n",
    "\n",
    "**Vậy mình sẽ chọn đáp án là b, In general, deterministic noise will increase.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2e83d862b3c5fd4fb57d72c50e8115f8",
     "grade": true,
     "grade_id": "c1",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Câu 2 (1 điểm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(file_name):\n",
    "    train_data = np.loadtxt(file_name)\n",
    "    X_train = train_data[:, :2]\n",
    "    Y_train = train_data[:, -1]\n",
    "    return X_train, Y_train\n",
    "\n",
    "def get_test_data(file_name):\n",
    "    test_data = np.loadtxt(file_name)\n",
    "    X_test = test_data[:, :2]\n",
    "    Y_test = test_data[:, -1]\n",
    "    return X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = get_train_data('in.dta')\n",
    "X_test, Y_test = get_test_data('out.dta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_linear_transform(X):\n",
    "    N = X.shape[0]\n",
    "    X = np.hstack((np.ones((N, 1)), X)) \n",
    "    x1 = X[:, 1].reshape(N, 1)\n",
    "    x2 = X[:, 2].reshape(N, 1)\n",
    "    X = np.hstack((X, x1**2))\n",
    "    X = np.hstack((X, x2**2))\n",
    "    X = np.hstack((X, x1 * x2))\n",
    "    X = np.hstack((X, np.abs(x1 - x2)))\n",
    "    X = np.hstack((X, np.abs(x1 + x2)))\n",
    "    return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_linear_regression(X, Y, lamd = 0):\n",
    "    XX = np.dot(X.T, X)\n",
    "    n = XX.shape[0]\n",
    "    X_dagger = np.dot(np.linalg.pinv(XX + lamd * np.eye(n)), X.T)\n",
    "    w = np.dot(X_dagger, Y)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fraction_error(X, Y, w):\n",
    "    error = np.mean(np.sign(np.dot(X, w)) != np.sign(Y))\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With lambda =  0.0\n",
      "Error_in :  0.02857142857142857\n",
      "Error out: 0.084\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression with Regularization and Non-linear Transformation\n",
    "#Lambda = 0.0 (No Regularization)\n",
    "X_train_transform = non_linear_transform(X_train)\n",
    "X_test_transform = non_linear_transform(X_test)\n",
    "lamd = 0.0\n",
    "w = run_linear_regression(X_train_transform, Y_train, lamd = lamd)\n",
    "E_in = get_fraction_error(X_train_transform, Y_train, w)\n",
    "E_out = get_fraction_error(X_test_transform, Y_test, w)\n",
    "print('With lambda = ', lamd)\n",
    "print('Error_in : ', E_in)\n",
    "print('Error out:', E_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Với bài tập Linear Regression này, kết quả cho $E_{in} = 0.02857142857142857$ và $E_{out} = 0.084$. **Mình chọn đáp án gần nhất với 2 kết quả lỗi này là a, 0.03, 0.08.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "47d4e2bb3e4812ef7b37e032a898cfec",
     "grade": true,
     "grade_id": "c2",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Câu 3 (1 điểm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With lambda =  0.001\n",
      "Error_in :  0.02857142857142857\n",
      "Error out: 0.08\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression with Regularization and Non-linear Transformation\n",
    "# Lambda = 10^-3\n",
    "X_train_transform = non_linear_transform(X_train)\n",
    "X_test_transform = non_linear_transform(X_test)\n",
    "lamd = 1e-3\n",
    "w = run_linear_regression(X_train_transform, Y_train, lamd = lamd)\n",
    "E_in = get_fraction_error(X_train_transform, Y_train, w)\n",
    "E_out = get_fraction_error(X_test_transform, Y_test, w)\n",
    "print('With lambda = ', lamd)\n",
    "print('Error_in : ', E_in)\n",
    "print('Error out:', E_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Với câu 3, ta thêm Regularization cho Linear Regression với $\\lambda = 10^{-3}$. Ta có kết quả độ lỗi lần lượt cho $E_{in} và E_{out}$ là 0.02857142857142857, 0.08. **Mình sẽ lựa chọn đạp án gần nhất là d.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0997a909d9ab1f250c2bfd0645fee970",
     "grade": true,
     "grade_id": "c3",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Câu 4 (1 điểm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With lambda =  1000.0\n",
      "Error_in :  0.37142857142857144\n",
      "Error out: 0.436\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression with Regularization and Non-linear Transformation\n",
    "# Lambda = 10^3\n",
    "X_train_transform = non_linear_transform(X_train)\n",
    "X_test_transform = non_linear_transform(X_test)\n",
    "lamd = 1e3\n",
    "w = run_linear_regression(X_train_transform, Y_train, lamd = lamd)\n",
    "E_in = get_fraction_error(X_train_transform, Y_train, w)\n",
    "E_out = get_fraction_error(X_test_transform, Y_test, w)\n",
    "print('With lambda = ', lamd)\n",
    "print('Error_in : ', E_in)\n",
    "print('Error out:', E_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Với câu 4, ta thêm Regularization với $\\lambda = 10^{3}$, ta có kết quả độ lỗi cho $E_{in}, E_{out}$ lần lượt là 0.37142857142857144, 0.436. **Mình sẽ chọn đáp án gần nhất là e, 0.4, 0.4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "efabab5c4035a6864ac8cb3e0061c6f0",
     "grade": true,
     "grade_id": "c4",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Câu 5 (1 điểm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K : -1\n",
      "Best error_out :  0.056\n"
     ]
    }
   ],
   "source": [
    "best_error_out = 1.0\n",
    "best_K = None\n",
    "X_train_transform = non_linear_transform(X_train)\n",
    "X_test_transform = non_linear_transform(X_test)\n",
    "for k in range(-10, 11):\n",
    "    lamd = pow(10, k)\n",
    "    w = run_linear_regression(X_train_transform, Y_train, lamd = lamd)\n",
    "    E_in = get_fraction_error(X_train_transform, Y_train, w)\n",
    "    E_out = get_fraction_error(X_test_transform, Y_test, w)\n",
    "    if E_out < best_error_out:\n",
    "        best_error_out = E_out\n",
    "        best_K = k\n",
    "print('Best K :', best_K)\n",
    "print('Best error_out : ', best_error_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ở đây chúng ta duyệt qua lần lượt các số K (biểu diễn cho giá trị lambda) để thêm Regularization cho bài toán Linear Regression. Ở đây K = -1 cho ta độ lỗi tốt nhất là 0.056. **Với câu 5, mình sẽ chọn là đáp án d, -1.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0b484b8390bec96142e8a1213ee8cd2c",
     "grade": true,
     "grade_id": "c5",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Câu 6 (1 điểm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Độ lỗi tốt nhất khi thêm Regularization là 0.056 từ đoạn code ở câu 5. **Nên mình chọn đáp án gần nhất là b, 0.06.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "26f542221236fb24d0ddbee584eed7d0",
     "grade": true,
     "grade_id": "c6",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Câu 7 (1 điểm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta sẽ kiểm tra cho từng đáp án.\n",
    "\n",
    "Ta có 1 nhận xét từ các biểu thức ràng buộc các hypothesis là :\n",
    "1. $H(Q, 0, Q_0) = H(Q_0 - 1)$, đây là một ràng buộc cho các tập Hypothesis bằng cách cho các bậc cao hơn có hệ sống bằng 0. \n",
    "\n",
    "2. $H(0) \\subset H(1) \\subset H(2) ... H(Q)$\n",
    "\n",
    "Với [a], $H(10, 0, 3) \\cup H(10, 0, 4) = H(2) \\cup H(3) = H(3)$. Vậy câu a sai.\n",
    "\n",
    "Với [b], $H(10, 1, 3) \\cup H(10, 1, 4) \\neq H(3)$. Đây là điều khá dễ thấy từ nhận xét ở trên.\n",
    "\n",
    "Với [c], $H(10, 0, 3) \\cap H(10, 0, 4) = H(2) \\cap H(3) = H(2)$. Với câu c thì ta nhận được 1 đáp án đúng.\n",
    "\n",
    "Với [d], $H(10, 1, 3) \\cap H(10, 1, 4) \\neq H(1)$. Đây là điều hiển nhiên tương tự như câu b.\n",
    "\n",
    "Vậy đáp án có biểu thức đúng là c."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "322a244b0fae3a20ec568a5099aaaec1",
     "grade": true,
     "grade_id": "c7",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Câu 8 (1 điểm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta có một fully connected Neural Network, với số lớp L = 2, $d^{(0)} = 5, d^{(1)} = 3, d^{(2)} = 1$. Ta sẽ đếm lần lượt các phép tính là: $w_{ij}^{(l)}x_i^{(l-1)} , w_{ij}^{(l)}\\delta_j^{(l)}, x_i^{(l - 1)}\\delta_j^{(l)}$\n",
    "\n",
    "Với phép tính $w_{ij}^{(l)}x_i^{(l-1)}$, ta có các phép tính này xuất hiện trong phần Lan truyền tiến (Forward-propagation): \n",
    "\n",
    "- Từ Lớp 0 đi qua Lớp 1 có (5 + 1) * 3 = 18 phép tính.\n",
    "\n",
    "- Từ Lớp 1 đi qua Lớp 2 có (3 + 1) * 1 = 4 phép tính. \n",
    "\n",
    "Vậy tổng cộng có **22 phép tính** $w_{ij}^{(l)}x_i^{(l-1)}$.\n",
    "\n",
    "Với phép tính $w_{ij}^{(l)}\\delta_j^{(l)}$, ta có các phép tính này xuất hiện trong phần Lan truyền ngược (Backpropagation):\n",
    "\n",
    "- Với Lớp 2, ta không cần phải tính $\\delta_0^{(2)}$ sử dụng phép tính trên, vì chúng ta sẽ tính đạo hàm đó từ độ lỗi cần tối ưu.\n",
    "\n",
    "- Ta chỉ cần sử dụng phép tính $w_{ij}^{(l)}\\delta_j^{(l)}$ trong lớp thứ 1, vì lớp 0 là lớp input không cần tính. Thêm nữa ta chỉ cần tính cho 3 node, trừ node 0 của Lớp 2 không có phép tính này, nên ta chỉ cần sử dụng **3 phép tính** $w_{ij}^{(l)}\\delta_j^{(l)}$.\n",
    "\n",
    "Với phép tính $x_i^{(l - 1)}\\delta_j^{(l)}$, chúng ta sử dụng chúng trong việc cập nhật lại các tham số $w_{ij}$ ở từng lớp, nên tương tự như với phép tính $w_{ij}^{(l)}x_i^{(l-1)}$, ta cũng sử dụng **22 phép tính**.\n",
    "\n",
    "**Vậy tổng cộng ta sử dụng 47 phép tính. Mình chọn đáp án gần nhất là 45, d**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d81773f072cd15e4a27b6cd240a5d990",
     "grade": true,
     "grade_id": "c8",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Câu 9 (1 điểm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta có một input gồm 10 unit (kể cả $x_0^{(0)}$) và một output với 1 unit. Ta có 36 hidden unit. \n",
    "\n",
    "Số lượng unit trong mạng nơ-ron này có số lượng tham số (weight) ít nhất là khi ta xếp mỗi lớp chỉ có một unit, ta có 36 lớp ẩn chỉ có 1 unit.\n",
    "\n",
    "**Vậy số lượng unit trong mạng này là: 10 * 1 + (1 * 1 * 35) + 1 * 1 = 46** (1 * 1 * 35 vì giữa 36 lớp thì 35 weighted matrix chứa các $w_{ij}$). Nên đáp án mình chọn là a, 46."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e814a2db0b8a53e4fddfee4bcbf405fc",
     "grade": true,
     "grade_id": "c9",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Câu 10 (1 điểm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum size of weighted w_ij 510\n",
      "Neural Network structure:\n",
      "u1 :  22\n",
      "u2 :  14\n"
     ]
    }
   ],
   "source": [
    "#With only 1 hidden layer with 36 hidden units in. We have 10 * 35 + 36 * 1 = 386 weights w_ij\n",
    "n_hidden = 36\n",
    "max_w_size = 386\n",
    "u1_max = None\n",
    "u2_max = None\n",
    "u3_max = None\n",
    "# Test with 2 hidden layers\n",
    "for u1 in range(1, n_hidden + 1):\n",
    "    for u2 in range(1, n_hidden + 1):\n",
    "        if u1 + u2 == n_hidden:\n",
    "            w_size = 10 * (u1 - 1) + u1 * (u2 - 1) + u2\n",
    "            if max_w_size < w_size:\n",
    "                max_w_size = w_size\n",
    "                u1_max = u1\n",
    "                u2_max = u2\n",
    "            \n",
    "# Test with 3 hidden layers\n",
    "for u1 in range(1, n_hidden + 1):\n",
    "    for u2 in range(1, n_hidden + 1):\n",
    "        for u3 in range(1, n_hidden + 1):\n",
    "            if u1 + u2 + u3 == n_hidden:\n",
    "                w_size = 10 * (u1 - 1) + u1 * (u2 - 1) + u2 * (u3 - 1) + u3\n",
    "                if max_w_size < w_size:\n",
    "                    max_w_size = w_size\n",
    "                    u1_max = u1\n",
    "                    u2_max = u2\n",
    "                    u3_max = u3\n",
    "                    \n",
    "print(\"maximum size of weighted w_ij\", max_w_size)\n",
    "print(\"Neural Network structure:\")\n",
    "if u1_max != None: \n",
    "    print(\"u1 : \", u1_max)\n",
    "if u2_max != None: \n",
    "    print(\"u2 : \", u2_max)\n",
    "if u3_max != None: \n",
    "    print(\"u3 : \", u3_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mình chạy đoạn code trên để thử các trường hợp có thể có của mạng với 2 Lớp hoặc 3 Lớp ẩn cho 36 unit ẩn trên. Mình có được 1 cấu trúc mạng cho ra số weight lớn nhất là $d^{(1)} = 22, d^{(2)} = 14$ với số weight đếm được là 510. **Nên đáp án của mình là e, 510.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "41cbf5c6d2b94eeae0a712be2181fef6",
     "grade": true,
     "grade_id": "c10",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
